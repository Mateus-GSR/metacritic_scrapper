{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL pattern for the pages\n",
    "url_pattern = 'https://www.metacritic.com/browse/movies/score/metascore/all/filtered?view=condensed&page={}'\n",
    "\n",
    "# Initialize lists to store the extracted values\n",
    "movie_names = []\n",
    "movie_hrefs = []\n",
    "\n",
    "# Iterate over the page numbers\n",
    "for page_number in range(155):\n",
    "    # Create the URL for the current page\n",
    "    url = url_pattern.format(page_number)\n",
    "\n",
    "    # Set headers to mimic a web browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers, allow_redirects=False)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Create a BeautifulSoup object from the response content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the div with the specified class\n",
    "        div = soup.find('div', {'class': 'title_bump'})\n",
    "\n",
    "        # Extract movie names and hrefs\n",
    "        if div:\n",
    "            titles = div.find_all('a', class_='title')\n",
    "            for title in titles:\n",
    "                # Find the <h3> element within the <a> element with the class \"title\"\n",
    "                h3_element = title.find('h3')\n",
    "                # Extract the movie name\n",
    "                movie_name = h3_element.get_text(strip=True)\n",
    "                # Extract the href attribute value\n",
    "                movie_href = title['href']\n",
    "                # Append the values to the respective lists\n",
    "                movie_names.append(movie_name)\n",
    "                movie_hrefs.append(movie_href)\n",
    "        else:\n",
    "            print(f\"Div not found on page {page_number}\")\n",
    "    else:\n",
    "        print(f\"Request failed on page {page_number}\")\n",
    "\n",
    "    # Add a delay of 5 seconds\n",
    "    time.sleep(5)\n",
    "\n",
    "# Create a DataFrame from the extracted values\n",
    "df_movies = pd.DataFrame({'Movie Name': movie_names, 'Movie Href': movie_hrefs})\n",
    "df_movies.to_csv('movies_href.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data transformation on the href column\n",
    "df_movies['Movie Href'] = df_movies['Movie Href'].apply(lambda x: 'https://www.metacritic.com' + x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_movie_title(soup):\n",
    "    try:\n",
    "        movie_title = soup.find('h1').get_text(strip=True)\n",
    "        return movie_title\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_director(soup):\n",
    "    try:\n",
    "        director_div = soup.find('div', class_='director')\n",
    "        director_name = director_div.a.span.text\n",
    "        return director_name\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_genres(soup):\n",
    "    try:\n",
    "        genres_div = soup.find('div', class_='genres')\n",
    "        genres_spans = genres_div.find_all('span')\n",
    "        genres = [span.text for span in genres_spans if span.text != ',']\n",
    "        combined_string = ' '.join(genres)\n",
    "        combined_string = re.sub(r'\\s+', ' ', combined_string.strip())\n",
    "        unique_words = re.findall(r'\\b\\w+\\b', combined_string)\n",
    "        unique_genres = set(unique_words)\n",
    "        return unique_genres\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_rating(soup):\n",
    "    try:\n",
    "        rating_div = soup.find('div', class_='rating')\n",
    "        rating = rating_div.get_text(strip=True).split(':')[1]\n",
    "        return rating\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_runtime(soup):\n",
    "    try:\n",
    "        runtime_div = soup.find('div', class_='runtime')\n",
    "        runtime = runtime_div.get_text(strip=True).split(':')[1]\n",
    "        return runtime\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_cast(soup):\n",
    "    try:\n",
    "        cast_div = soup.find('div', class_='summary_cast details_section')\n",
    "        cast_name = cast_div.get_text(strip=True).split(':')[1]\n",
    "        return cast_name\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_distributor(soup):\n",
    "    try:\n",
    "        distributor_div = soup.find('span', class_='distributor')\n",
    "        distributor_name = distributor_div.find('a').text\n",
    "        return distributor_name\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_release_date(soup):\n",
    "    try:\n",
    "        release_date_div = soup.find('span', class_='release_date')\n",
    "        release_date = release_date_div.get_text(strip=True).split(':')[1]\n",
    "        return release_date\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_summary(soup):\n",
    "    try:\n",
    "        summary_div = soup.find('span', class_='blurb blurb_expanded')\n",
    "        summary = summary_div.get_text(strip=True).split(':')\n",
    "        return summary\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_metascore(soup):\n",
    "    try:\n",
    "        metascore_div = soup.find_all(class_='score fl')[0]\n",
    "        metascore = metascore_div.text.strip()\n",
    "        return metascore\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_metascore_ratings(soup):\n",
    "    try:\n",
    "        metascore_positive_count = soup.find_all(class_='chart positive')[0].find(class_='count fr').text\n",
    "        metascore_mixed_count = soup.find_all(class_='chart mixed')[0].find(class_='count fr').text\n",
    "        metascore_negative_count = soup.find_all(class_='chart negative')[0].find(class_='count fr').text\n",
    "        return metascore_positive_count, metascore_mixed_count, metascore_negative_count\n",
    "    except AttributeError:\n",
    "        return \"null\", \"null\", \"null\"\n",
    "\n",
    "def find_userscore(soup):\n",
    "    try:\n",
    "        user_score_div = soup.find_all(class_='score fl')[1]\n",
    "        user_score = user_score_div.text.strip()\n",
    "        return user_score\n",
    "    except AttributeError:\n",
    "        return \"null\"\n",
    "\n",
    "def find_userscore_ratings(soup):\n",
    "    try:\n",
    "        user_score_positive_count = soup.find_all(class_='chart positive')[1].find(class_='count fr').text\n",
    "        user_score_mixed_count = soup.find_all(class_='chart mixed')[1].find(class_='count fr').text\n",
    "        user_score_negative_count = soup.find_all(class_='chart negative')[1].find(class_='count fr').text\n",
    "        return user_score_positive_count, user_score_mixed_count, user_score_negative_count\n",
    "    except AttributeError:\n",
    "        return \"null\", \"null\", \"null\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to scrape data from a single URL\n",
    "def scrape_movie_data(url):\n",
    "    try:\n",
    "        user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(url, headers=user_agent)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Call the functions to extract the data\n",
    "        title = find_movie_title(soup)\n",
    "        director = find_director(soup)\n",
    "        genres = find_genres(soup)\n",
    "        rating = find_rating(soup)\n",
    "        runtime = find_runtime(soup)\n",
    "        cast = find_cast(soup)\n",
    "        distributor = find_distributor(soup)\n",
    "        release_date = find_release_date(soup)\n",
    "        summary = find_summary(soup)\n",
    "        metascore = find_metascore(soup)\n",
    "        metascore_positive, metascore_mixed, metascore_negative = find_metascore_ratings(soup)\n",
    "        userscore = find_userscore(soup)\n",
    "        userscore_positive, userscore_mixed, userscore_negative = find_userscore_ratings(soup)\n",
    "\n",
    "        # Create a dictionary with the extracted data\n",
    "        data = {\n",
    "            'Title': [title],\n",
    "            'Director': [director],\n",
    "            'Genres': [genres],\n",
    "            'Rating': [rating],\n",
    "            'Runtime': [runtime],\n",
    "            'Cast': [cast],\n",
    "            'Distributor': [distributor],\n",
    "            'Release Date': [release_date],\n",
    "            'Summary': [summary],\n",
    "            'Metascore': [metascore],\n",
    "            'Metascore Positive': [metascore_positive],\n",
    "            'Metascore Mixed': [metascore_mixed],\n",
    "            'Metascore Negative': [metascore_negative],\n",
    "            'Userscore': [userscore],\n",
    "            'Userscore Positive': [userscore_positive],\n",
    "            'Userscore Mixed': [userscore_mixed],\n",
    "            'Userscore Negative': [userscore_negative]\n",
    "        }\n",
    "\n",
    "        return data\n",
    "    except:\n",
    "        # If an exception occurs (e.g., missing URL)\n",
    "        return None\n",
    "\n",
    "# Create an empty list to store the data from each URL\n",
    "all_data = []\n",
    "\n",
    "# Iterate over the URLs in the 'Movie Href' column\n",
    "for url in df_movies['Movie Href']:\n",
    "    # Call the function to scrape data from the URL\n",
    "    data = scrape_movie_data(url)\n",
    "    \n",
    "    if data is not None:\n",
    "        all_data.append(data)\n",
    "\n",
    "     # Add a wait time of 5 seconds before the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "# Create a DataFrame from the obtained data\n",
    "df = pd.concat([pd.DataFrame(d) for d in all_data], ignore_index=True)\n",
    "df.to_csv('movies_metadata_metacritic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
